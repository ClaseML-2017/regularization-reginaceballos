{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Regina Ceballos Mondragón\n",
    "147663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y estandarización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ClaseML-2017/MaterialyTareas/master/datos/regLinPoli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('y', axis=1), df[['y']], train_size=0.75)\n",
    "X_train, X_test, Y_train, Y_test = np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)\n",
    "scalerX = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scalerX.transform(X_train)\n",
    "X_test = scalerX.transform(X_test)\n",
    "scalerY = preprocessing.StandardScaler().fit(Y_train)\n",
    "Y_train = scalerY.transform(Y_train)\n",
    "Y_test = scalerY.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal Iterativa Regularizada\n",
    "### Lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((np.ones((len(X_train), 1)), X_train), axis=1)\n",
    "w = np.ones((1,len(X[0])))\n",
    "eta = 0.05\n",
    "lam = 0.0\n",
    "for i in range(0, len(X)):\n",
    "    V = np.dot(w, X[i])\n",
    "    w[0][0] += eta * (Y_train[i]- V)\n",
    "    for j in range (1, len(w[0])):\n",
    "        w[0][j] += eta * (Y_train[i]- V) * X[i][j] + lam * w[0][j] \n",
    "error = np.mean((Y_test - w[0][0] - np.dot(X_test, np.delete(w,0)))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96470669619\n"
     ]
    }
   ],
   "source": [
    "print error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.ones((1,len(X[0])))\n",
    "eta = 0.05\n",
    "lam = 0.001\n",
    "for i in range(0, len(X)):\n",
    "    V = np.dot(w, X[i])\n",
    "    w[0][0] += eta * (Y_train[i]- V)\n",
    "    for j in range (1, len(w[0])):\n",
    "        w[0][j] += eta * (Y_train[i]- V) * X[i][j] + lam * w[0][j] \n",
    "error = np.mean((Y_test - w[0][0] - np.dot(X_test, np.delete(w,0)))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98628111498\n"
     ]
    }
   ],
   "source": [
    "print error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos datos, es mejor no regularizar. Como vimos en clase, esto se debe a que hay suficientes datos para ajustar. Cabe notar que si no se estandarizan las y's, el error aumenta mucho y los coeficientes tambien son enormes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
